# ğŸ”¬ METODOLOJI (METHODOLOGY)

## Ä°statistiksel Testler

### Hipotez Testleri
```python
# 1. Independent t-test: React vs non-React maaÅŸ karÅŸÄ±laÅŸtÄ±rmasÄ±
H0: Î¼_react = Î¼_non_react
H1: Î¼_react â‰  Î¼_non_react

# 2. One-way ANOVA: Lokasyon bazlÄ± maaÅŸ farklarÄ±
H0: Î¼_turkey = Î¼_europe = Î¼_other
H1: En az bir grup farklÄ±

# 3. Chi-square test: Cinsiyet vs teknoloji tercihi baÄŸÄ±msÄ±zlÄ±ÄŸÄ±
H0: Cinsiyet ve teknoloji tercihi baÄŸÄ±msÄ±z
H1: Cinsiyet ve teknoloji tercihi baÄŸÄ±mlÄ±

# 4. Pearson correlation: Deneyim vs maaÅŸ iliÅŸkisi
H0: Ï = 0 (Korelasyon yok)
H1: Ï â‰  0 (Korelasyon var)
```

### GÃ¼ven AralÄ±klarÄ±
- **Confidence Level**: 95% (Î± = 0.05)
- **Effect Size**: Cohen's d, eta-squared
- **Power Analysis**: Minimum sample size hesaplamasÄ±

## Machine Learning Models

### Regresyon Modelleri
```python
# 1. Linear Regression (baseline)
from sklearn.linear_model import LinearRegression
# Baseline model olarak kullanÄ±lacak

# 2. Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
# Non-linear iliÅŸkileri yakalama

# 3. XGBoost Regressor
import xgboost as xgb
# Gradient boosting ile performans optimizasyonu

# 4. Feature importance analysis
# Her model iÃ§in feature importance hesaplama
```

### Clustering
```python
# 1. K-means clustering (Developer personas)
from sklearn.cluster import KMeans
# Elbow method ile optimal k deÄŸeri

# 2. Hierarchical clustering (Stack combinations)
from sklearn.cluster import AgglomerativeClustering
# Dendrogram ile gÃ¶rselleÅŸtirme
```

### Model DeÄŸerlendirme
```python
# Cross-validation
from sklearn.model_selection import cross_val_score

# Metrics
- RÂ² Score (AÃ§Ä±klama gÃ¼cÃ¼)
- Mean Absolute Error (MAE)
- Root Mean Square Error (RMSE)
- Adjusted RÂ² (Feature sayÄ±sÄ±na gÃ¶re dÃ¼zeltilmiÅŸ)
```

## Veri Ä°ÅŸleme AdÄ±mlarÄ±

### 1. Data Cleaning
- **MaaÅŸ Normalizasyonu**: "61-70" â†’ 65 (aralÄ±k ortalamasÄ±)
- **Teknoloji AyrÄ±ÅŸtÄ±rma**: "React, Redux" â†’ ayrÄ± dummy variables
- **Kategorik Kodlama**: Label encoding ve one-hot encoding
- **Missing Values**: Imputation stratejileri

### 2. Feature Engineering
- **Skill Dummy Variables**: Her teknoloji iÃ§in binary column
- **Experience Numeric**: String deneyim â†’ sayÄ±sal deÄŸer
- **Interaction Terms**: Teknoloji Ã— deneyim kombinasyonlarÄ±
- **Polynomial Features**: Non-linear iliÅŸkiler iÃ§in

### 3. Outlier Detection
- **IQR Method**: Q1 - 1.5*IQR, Q3 + 1.5*IQR
- **Z-Score**: |z| > 3 olan deÄŸerler
- **Isolation Forest**: ML-based outlier detection

### 4. Normalization
- **PPP-adjusted**: SatÄ±n alma gÃ¼cÃ¼ paritesi
- **Standard Scaling**: Z-score normalization
- **Min-Max Scaling**: [0,1] aralÄ±ÄŸÄ±na Ã§evirme

## Ä°statistiksel GÃ¼Ã§ Analizi

### Sample Size Calculation
```python
# Minimum sample size hesaplamasÄ±
# Effect size = 0.3 (medium effect)
# Power = 0.8
# Alpha = 0.05

# T-test iÃ§in: n = 64 per group
# ANOVA iÃ§in: n = 52 per group
# Correlation iÃ§in: n = 84 total
```

### Effect Size Interpretation
- **Cohen's d**: 0.2 (small), 0.5 (medium), 0.8 (large)
- **Eta-squared**: 0.01 (small), 0.06 (medium), 0.14 (large)
- **RÂ²**: 0.02 (small), 0.13 (medium), 0.26 (large)

## Veri Kalitesi KontrolÃ¼

### Data Quality Metrics
- **Completeness**: Eksik veri oranÄ±
- **Consistency**: TutarlÄ±lÄ±k kontrolÃ¼
- **Accuracy**: DoÄŸruluk kontrolÃ¼
- **Timeliness**: GÃ¼ncellik

### Validation Steps
1. **Data Profiling**: Temel istatistikler
2. **Distribution Analysis**: Normal daÄŸÄ±lÄ±m kontrolÃ¼
3. **Correlation Analysis**: Multicollinearity tespiti
4. **Outlier Analysis**: Anomali tespiti

## Raporlama StandartlarÄ±

### Ä°statistiksel Raporlama
- **APA Format**: Statistical reporting standards
- **Effect Sizes**: Her test iÃ§in effect size
- **Confidence Intervals**: %95 gÃ¼ven aralÄ±klarÄ±
- **P-values**: Exact p-values (p < 0.001)

### Model Performance Reporting
- **Cross-validation Results**: Mean Â± SD
- **Feature Importance**: Ranked list
- **Residual Analysis**: Normality, homoscedasticity
- **Model Comparison**: Statistical significance
